{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dbscan_clustering .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manchann/secure_project2/blob/main/dbscan_clustering_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLoQ2s-Lb8uM"
      },
      "source": [
        "- **이상값 가정 1**\n",
        "    \n",
        "    정상값들은 하나 또는 몇 개의 군집에 모여 있고, 이상값은 군집에 속하지 않는다.\n",
        "    \n",
        "    데이터에서 군집을 찾아낸 후 제거한 뒤 남아있는 데이터를 이상값으로 처리**.**\n",
        "    \n",
        "    DBSCAN ( [wikipedia 설명](https://en.wikipedia.org/wiki/DBSCAN) , [scikit-learn 의 DBSCAN 알고리즘](https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html) )ROCK ( [Guha et al., 2000](http://www.facweb.iitkgp.ac.in/~shamik/autumn2012/dwdm/papers/ROCK%20A%20Robust%20Clustering%20Algorithm%20for%20Categorical%20Attributes%20(2000)guha00rock.pdf) )SNN 군집화 ( [ML wiki 설명](http://mlwiki.org/index.php/SNN_Clustering) )\n",
        "    \n",
        "- **이상값 가정 2**\n",
        "    \n",
        "    **군집의 중심(centroid) 중 가장 가까운 것과의 거리가 짧으면 정상값, 길면 이상값이다.**\n",
        "    \n",
        "    **군집화를 하고 데이터가 포함된 군집의 중심과 데이터 개체 사이의 거리를 “이상 score” 로 두고 이용.**\n",
        "    \n",
        "    K-means ( [wikipedia 설명](https://ko.wikipedia.org/wiki/K-%ED%8F%89%EA%B7%A0_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98) )EM 알고리즘 ( [wikipedia 설명](https://ko.wikipedia.org/wiki/%EA%B8%B0%EB%8C%93%EA%B0%92_%EC%B5%9C%EB%8C%80%ED%99%94_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98) )\n",
        "    \n",
        "- **이상값 가정 3**\n",
        "    \n",
        "    **정상값은 크거나 조밀한 군집에, 이상값은 작거나 sparse 한 군집에 속한다.**\n",
        "    \n",
        "    데이터 개체가 속한 군집의 크기나 밀도가 “이상” 여부를 판단."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtc84QFRcEBk"
      },
      "source": [
        "## 이상값 가정 1 : DBSCAN 알고리즘 적용\n",
        "밀도 방식의 클러스터링을 사용하는 DBSCAN(Density-based spatial clustering of applications with noise)\n",
        "\n",
        "앞에서 설명한 K Means나 Hierarchical 클러스터링의 경우 군집간의 거리를 이용하여 클러스터링을 하는 방법인데, 밀도 기반의 클러스터링은 점이 세밀하게 몰려 있어서 밀도가 높은 부분을 클러스터링 하는 방식이다. 쉽게 설명하면, 어느점을 기준으로 반경 x내에 점이 n개 이상 있으면 하나의 군집으로 인식하는 방식이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZlLenFpcaxO"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot  as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvlhTk9u7gcW"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q-k_fAxKf9L",
        "outputId": "4533359e-231b-45c0-cff1-4eb3c95d78db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qxW1YJ7W7XeI",
        "outputId": "8c70dbe4-e42b-4f43-dbe2-6d449463e5a2"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/BigData/04_hashed.csv\")\n",
        "\n",
        "dataset.columns\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rdate</th>\n",
              "      <th>src_ip</th>\n",
              "      <th>dst_ip</th>\n",
              "      <th>Proto</th>\n",
              "      <th>src_port</th>\n",
              "      <th>dst_port</th>\n",
              "      <th>Action</th>\n",
              "      <th>src_country</th>\n",
              "      <th>dst_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.021041e+13</td>\n",
              "      <td>154.58.159.102</td>\n",
              "      <td>103.177.12.42</td>\n",
              "      <td>6</td>\n",
              "      <td>52897</td>\n",
              "      <td>445</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.021041e+13</td>\n",
              "      <td>154.58.159.20</td>\n",
              "      <td>125.66.92.196</td>\n",
              "      <td>6</td>\n",
              "      <td>60579</td>\n",
              "      <td>445</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>DE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.021041e+13</td>\n",
              "      <td>154.58.159.164</td>\n",
              "      <td>117.121.178.223</td>\n",
              "      <td>6</td>\n",
              "      <td>63831</td>\n",
              "      <td>445</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.021041e+13</td>\n",
              "      <td>154.58.159.165</td>\n",
              "      <td>205.34.95.97</td>\n",
              "      <td>6</td>\n",
              "      <td>55241</td>\n",
              "      <td>445</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.021041e+13</td>\n",
              "      <td>154.58.159.102</td>\n",
              "      <td>93.56.164.131</td>\n",
              "      <td>6</td>\n",
              "      <td>52898</td>\n",
              "      <td>445</td>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>US</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Rdate          src_ip  ... src_country  dst_country\n",
              "0  2.021041e+13  154.58.159.102  ...        None           US\n",
              "1  2.021041e+13   154.58.159.20  ...        None           DE\n",
              "2  2.021041e+13  154.58.159.164  ...        None           US\n",
              "3  2.021041e+13  154.58.159.165  ...        None           US\n",
              "4  2.021041e+13  154.58.159.102  ...        None           US\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIL17QYVyrsr",
        "outputId": "f085df5d-360e-4848-e774-e576d17531be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# def select_unique_Rdate(dataset):\n",
        "#   time_list=[]\n",
        "#   for i in range(len(dataset['Rdate'])):\n",
        "#     time_list.append(dataset.iloc[i]['Rdate'])\n",
        "#   unique_time = set(time_list)\n",
        "#   unique_time = sorted(unique_time)\n",
        "#   print(len(unique_time)) # 24218\n",
        "#   return unique_time \n",
        "start_time = 20210411000000\n",
        "get_days = 1000000\n",
        "\n",
        "dataset_origin = dataset\n",
        "\n",
        "dataset = dataset[dataset['Rdate'] < 20210411000000 ]\n",
        "\n",
        "dataset.tail()\n",
        "\n",
        "dataset.loc[2861154]['Rdate']\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20210410235916.727"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDK2En8Q7a3R"
      },
      "source": [
        "# feature = dataset[ ['src_ip', 'dst_ip', 'Proto', 'src_port', 'dst_port', 'Action',\n",
        "#        'src_country', 'dst_country'] ]\n",
        "\n",
        "feature = dataset[['Rdate','src_ip', 'dst_ip', 'src_port', 'dst_port', 'Action']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv4pIhG78HeR"
      },
      "source": [
        "# IPv4 전처리\n",
        "def transform_ip(ip): \n",
        "  groups = ip.split(\".\") \n",
        "  equalize_group_length = \"\".join( map( lambda group: group.zfill(3), groups )) \n",
        "  return equalize_group_length \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Feature 전처리\n",
        "def preprocess_df(df):\n",
        "  \n",
        "  # IPv4 전처리\n",
        "  df['src_ip'] = df.src_ip.apply(lambda ip : transform_ip(ip))\n",
        "  df['dst_ip'] = df.dst_ip.apply(lambda ip : transform_ip(ip))\n",
        "\n",
        "  # country 전처리\n",
        "  label_encoder = LabelEncoder()\n",
        "  df['src_country'] = label_encoder.fit_transform(df['src_country'])\n",
        "  df['dst_country'] = label_encoder.fit_transform(df['dst_country'])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yr0a74p8Nk0"
      },
      "source": [
        "dataset = preprocess_df(dataset)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg96hB3GAbtc"
      },
      "source": [
        "DBSCAN의  매개변수들\n",
        "\n",
        "- DBSCAN의 주 매개변수\n",
        "    - **min_samples** : 핵심 포인트를 중심점으로 간주하는 주변 지역의 표본 수\n",
        "    - **eps** : 핵심 포인트를 중심으로 측정되는 유클리디언 거리값\n",
        "- **밀집지역(dense region)** : 특성 공간에서 (거리가 가까워서) 데이터가 붐비는 지역\n",
        "- **핵심 샘플(or 핵심 포인트)** : eps거리 안에 데이터가 지정한 min_samples개수를 만족시키는 밀집지역에 있는 데이터 포인트\n",
        "- **잡음(noise)** : eps거리 안에 들어오는 포인트 수가 지정한 min_sample보다 적을 경우 어디에도 속하지 않는 잡음으로 레이블됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ5hOxNOAgxq"
      },
      "source": [
        "DBSCAN 작동 방식 \n",
        "\n",
        "- **STEP 1** : 특성 공간에서 데이터가 붐비는 밀집지역을 찾고, 그 범위안에서 핵심 샘플이될 포인트를 지정한다.\n",
        "- **STEP 2** : 어느 데이터 포인트에서 eps거리 안에 데이터가 min_samples개수 만큼 들어 있으면 이 데이터 포인트를 핵심 샘플로 지정한다. 이 경우 해당 데이터 포인트는 새로운 클러스터 레이블로 할당된다. (min_samples개수를 충족시키지 않으면 잡음으로 분류)\n",
        "- **STEP 3** : 새롭게 할당된 핵심 샘플로 부터 eps거리 안의 포인트가 만약 어떤 클러스터에도 할당되지 않았다면 해당 클러스터 레이블로 할당시킨다. (만약 핵심 샘플이면 그 포인트의 이웃을 차례로 방문)\n",
        "- **STEP 4** : STEP 1~3을 반복하며 eps거리 안에 더 이상 핵심 샘플이 없을 때까지 자란다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WV0iIl5APxN"
      },
      "source": [
        "# #############################################################################\n",
        "# Compute DBSCAN\n",
        "def dbscan(feature_):\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  feature = feature_[ ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'Action']]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  scaler.fit(feature)\n",
        "  feature_trans = scaler.transform(feature)\n",
        "  model = DBSCAN(eps=0.5, min_samples=5)\n",
        "  predict = pd.DataFrame(model.fit_predict(feature_trans))\n",
        "  predict.columns = ['predict']\n",
        "  r = pd.concat([feature,predict],axis=1)\n",
        "  \n",
        "  # core_samples_mask = np.zeros_like(model.labels_, dtype=bool)\n",
        "  # core_samples_mask[model.core_sample_indices_] = True\n",
        "  labels = model.labels_\n",
        "\n",
        "  n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "  n_noise_ = list(labels).count(-1)\n",
        "\n",
        "  print(\"Dataset Size : \",len(feature))\n",
        "  print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
        "  print(\"Estimated number of noise points: %d\" % n_noise_)\n",
        "  return r, labels"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiEWaaHpARyk"
      },
      "source": [
        "def pair_plot(r):\n",
        "  sns.pairplot(r,hue='predict')\n",
        "  plt.show()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89XBRji2jqC"
      },
      "source": [
        "# window size 만큼의의 데이터 추출\n",
        "dbscan_result = dbscan(dataset)\n",
        "pair_plot(dbscan_result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9htT8i3-vwY"
      },
      "source": [
        "anomaly_data = dbscan_result[dbscan_result['predict']==-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVPfkJWoD3Bp"
      },
      "source": [
        "anomaly_data.to_csv(\"/content/drive/MyDrive/dbscan_anomaly_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQvK47j1G-wo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
